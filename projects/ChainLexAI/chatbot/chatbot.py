# -*- coding: utf-8 -*-
"""
RWAä»£å¸å‘è¡Œè¯´æ˜ä¹¦æ™ºèƒ½äº¤äº’Agentç³»ç»Ÿ - åŸºäºLangGraphçš„å¤šå·¥å…·Graphæ¶æ„
æ”¹é€ è‡ªtest-graph-demo.pyï¼Œå®ç°å¤šå·¥å…·ã€å¤šèŠ‚ç‚¹çš„graph-basedæ™ºèƒ½äº¤äº’agentç³»ç»Ÿ
"""
import re
import json
from pathlib import Path
from typing import Dict, List, Optional, Tuple, TypedDict, Literal, Any
from datetime import datetime

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain.agents import AgentExecutor, create_openai_tools_agent, AgentType
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import InMemorySaver

# ==================== çŠ¶æ€å®šä¹‰ ====================
class DocumentState(TypedDict):
    """æ–‡æ¡£å¡«å†™çŠ¶æ€ - å¢å¼ºç‰ˆæœ¬æ”¯æŒAgentäº¤äº’"""
    current_section: int  # å½“å‰å¤„ç†çš„ç« èŠ‚ (0-11)
    section_contents: Dict[str, Dict[str, str]]  # æ¯ä¸ªç« èŠ‚çš„å†…å®¹
    filled_placeholders: Dict[str, Dict[str, str]]  # å·²å¡«å†™çš„å ä½ç¬¦
    pending_placeholders: Dict[str, List[str]]  # å¾…å¡«å†™çš„å ä½ç¬¦
    interaction_mode: str  # "ask" | "fill" | "confirm" | "auto"
    conversation_history: List[Dict[str, str]]  # å¯¹è¯å†å²
    last_user_input: str  # æœ€è¿‘ç”¨æˆ·è¾“å…¥
    ai_summary: str  # AIç”Ÿæˆçš„æ‘˜è¦
    agent_response: str  # Agentçš„å“åº”
    section_complete: bool  # å½“å‰ç« èŠ‚æ˜¯å¦å®Œæˆ
    extracted_info: Dict[str, Any]  # æå–çš„ç»“æ„åŒ–ä¿¡æ¯

# ==================== æ–‡æ¡£é…ç½® ====================
SECTION_TITLES = [
    "æ‰§è¡Œæ‘˜è¦ï¼ˆExecutive Summaryï¼‰",
    "å‘è¡Œä¸»ä½“ä¸æ²»ç†ï¼ˆIssuer & Governanceï¼‰",
    "ä»£å¸æ¦‚è§ˆä¸åˆ†ç±»ï¼ˆToken Overview & Classificationï¼‰",
    "æ³•å¾‹ä¸åˆè§„ï¼ˆLegal & Regulatoryï¼‰",
    "Tokenomicsï¼ˆä¾›ç»™ã€åˆ†é…ã€è§£é”ã€é‡‘åº“ï¼‰",
    "å‹Ÿé›†å†å²ä¸èµ„é‡‘ç”¨é€”ï¼ˆFundraising & Use of Proceedsï¼‰",
    "æŠ€æœ¯ä¸å®‰å…¨ï¼ˆTechnology & Securityï¼‰",
    "ä¸Šå¸‚ä¸äº¤æ˜“å®‰æ’ï¼ˆListing & Tradingï¼‰",
    "å¸‚åœºè¯šä¿¡ä¸ä¿¡æ¯æŠ«éœ²ï¼ˆMarket Integrity & Disclosuresï¼‰",
    "ä¸»è¦é£é™©ï¼ˆKey Risksï¼‰",
    "äº‹ä»¶å“åº”ä¸ä¸‹æ¶ï¼ˆIncident & Delistingï¼‰",
    "å£°æ˜ä¸ç­¾ç½²ï¼ˆDeclarationsï¼‰"
]

SECTION_NAMES = [f"section_{i}" for i in range(12)]

# ==================== æ™ºèƒ½å»ºè®®çŸ¥è¯†åº“ ====================
SUGGESTION_TEMPLATES = {
    "executive_summary": {
        "token_name": ["CloudComputer Token", "CCT", "CloudRWA", "CRWT"],
        "asset_nature": ["å€ºæƒ", "æ”¶ç›Šæƒ", "åŸºé‡‘ä»½é¢", "ç¥¨æ®"],
        "target_market": ["ä¸“ä¸šæŠ•èµ„è€…ï¼ˆPIï¼‰", "ä»…æœºæ„æŠ•èµ„è€…", "åˆæ ¼æŠ•èµ„è€…"],
        "risk_summary": ["æŠ€æœ¯å®æ–½é£é™©", "ç›‘ç®¡åˆè§„é£é™©", "æµåŠ¨æ€§é£é™©"]
    },
    "legal_compliance": {
        "offering_route": ["ç§å‹Ÿï¼ˆä¸“ä¸šæŠ•èµ„è€…ï¼Œâ‰¤50äººï¼Œå•ç¬”â‰¥HKD 500kï¼‰", "å…¬å‹Ÿï¼ˆéœ€è¦ç›¸åº”ç›‘ç®¡æˆæƒï¼‰"],
        "jurisdiction": ["é¦™æ¸¯(SFC)", "æ–°åŠ å¡(MAS)", "é˜¿è”é…‹(ADGM)", "æ¬§ç›ŸMiCA"],
        "kyc_provider": ["Chainalysis", "Sumsub", "IdentityMind", "Onfido"]
    },
    "tokenomics": {
        "total_supply": ["100,000,000", "1,000,000,000", "10,000,000,000"],
        "team_allocation": "15-20%",
        "community_allocation": "30-40%",
        "ecosystem_allocation": "20-25%",
        "liquidity_allocation": "10-15%"
    },
    "technical_security": {
        "blockchain": ["Ethereum", "BNB Chain", "Arbitrum", "Polygon", "Base"],
        "audit_firm": ["CertiK", "Quantstamp", "Trail of Bits", "OpenZeppelin"],
        "custody": ["Fireblocks", "Anchorage Digital", "Coinbase Prime", "BitGo"]
    }
}

# ==================== å¤šå·¥å…·å±‚ï¼ˆToolsï¼‰====================
@tool
def extract_info_tool(text: str) -> str:
    """
    è§£æç”¨æˆ·è¾“å…¥ï¼Œæå–ç»“æ„åŒ–å­—æ®µä¿¡æ¯

    Args:
        text: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¾“å…¥

    Returns:
        JSONæ ¼å¼çš„ç»“æ„åŒ–ä¿¡æ¯å­—ç¬¦ä¸²
    """
    extracted = {}

    # æå–ä»£å¸ç›¸å…³ä¿¡æ¯
    token_patterns = {
        "token_name": r"(?:ä»£å¸|token|å¸ç§|åç§°)[:ï¼š\s]*([A-Za-z]{2,})",
        "token_symbol": r"(?:ç®€ç§°|ç¬¦å·|symbol)[:ï¼š\s]*([A-Z]{2,5})",
        "total_supply": r"(?:æ€»é‡|å‘è¡Œé‡|supply)[:ï¼š\s]*([0-9,]+)",
        "blockchain": r"(?:é“¾|ç½‘ç»œ|blockchain|chain)[:ï¼š\s]*([A-Za-z\s]+)",
        "date": r"(?:æ—¥æœŸ|æ—¶é—´|date)[:ï¼š\s]*(\d{4}[-/]\d{1,2}[-/]\d{1,2})"
    }

    for field, pattern in token_patterns.items():
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            extracted[field] = match.group(1).strip()

    # æå–å†³ç­–æ¨¡å¼
    if any(keyword in text.lower() for keyword in ["ä½ æ¥å†³å®š", "ä½ å†³å®šå§", "è‡ªåŠ¨å¡«", "å†³å®šå§"]):
        extracted["decision_mode"] = "auto_fill"
    elif any(keyword in text.lower() for keyword in ["å»ºè®®", "æ¨è", "æ¨è"]):
        extracted["decision_mode"] = "suggest"
    else:
        extracted["decision_mode"] = "user_direct"

    # æå–ç« èŠ‚ç›¸å…³ä¿¡æ¯
    if "spv" in text.lower():
        extracted["entity_structure"] = "SPV"
    elif "åŸºé‡‘" in text:
        extracted["entity_structure"] = "åŸºé‡‘"

    if "certik" in text.lower():
        extracted["audit_firm"] = "CertiK"
    elif "quantstamp" in text.lower():
        extracted["audit_firm"] = "Quantstamp"

    return json.dumps(extracted, ensure_ascii=False, indent=2)

@tool
def autofill_tool(state_json: str) -> str:
    """
    æ ¹æ®ä¸Šä¸‹æ–‡è¡¥é½æœªå¡«å†™å†…å®¹

    Args:
        state_json: DocumentStateçš„JSONå­—ç¬¦ä¸²

    Returns:
        è‡ªåŠ¨å¡«å†™çš„å†…å®¹æè¿°
    """
    try:
        state_data = json.loads(state_json)
        current_section_idx = state_data.get("current_section", 0)
        section_name = SECTION_NAMES[current_section_idx]

        # æ¨¡æ‹Ÿä¸€äº›å¾…å¡«å†™çš„å ä½ç¬¦
        pending_placeholders = [
            "ä»£å¸åç§°", "åˆçº¦åœ°å€", "èµ„äº§æ€§è´¨", "ç›®æ ‡å¸‚åœº",
            "å‘è¡Œç»“æ„", "å®¡è®¡æœºæ„", "æ³•åŸŸé€‰æ‹©", "KYCæä¾›å•†"
        ]

        filled_content = {}

        for placeholder in pending_placeholders:
            suggestion = get_smart_suggestion(placeholder, section_name)
            filled_content[placeholder] = suggestion

        result = {
            "action": "autofill_complete",
            "section": section_name,
            "filled_items": filled_content,
            "message": f"å·²è‡ªåŠ¨å¡«å†™ {len(filled_content)} é¡¹å†…å®¹"
        }

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        return json.dumps({"error": f"è‡ªåŠ¨å¡«å†™å¤±è´¥: {str(e)}"}, ensure_ascii=False)

@tool
def summarize_tool(state_json: str) -> str:
    """
    æ€»ç»“å½“å‰ç« èŠ‚å®Œæ•´è‰ç¨¿

    Args:
        state_json: DocumentStateçš„JSONå­—ç¬¦ä¸²

    Returns:
        ç« èŠ‚æ€»ç»“å†…å®¹
    """
    try:
        state_data = json.loads(state_json)
        current_section_idx = state_data.get("current_section", 0)
        section_name = SECTION_NAMES[current_section_idx]

        # æ¨¡æ‹Ÿä¸€äº›å·²å¡«å†™çš„å†…å®¹
        filled = {
            "ä»£å¸åç§°": "CCT (CloudComputer Token)",
            "èµ„äº§æ€§è´¨": "å€ºæƒ",
            "ç›®æ ‡å¸‚åœº": "ä¸“ä¸šæŠ•èµ„è€…ï¼ˆPIï¼‰",
            "å‘è¡Œç»“æ„": "SPV",
            "å®¡è®¡æœºæ„": "CertiK"
        }

        summary = f"""
ğŸ“‹ ç¬¬{current_section_idx}èŠ‚ {SECTION_TITLES[current_section_idx]} å®Œæˆæƒ…å†µï¼š

âœ… å·²å¡«å†™å†…å®¹ ({len(filled)} é¡¹)ï¼š
"""

        for i, (key, value) in enumerate(filled.items(), 1):
            summary += f"   {i}. {key}: {value}\n"

        if not filled:
            summary += "   æš‚æ— å¡«å†™å†…å®¹\n"

        summary += f"\nğŸ“Š å®Œæˆåº¦ï¼š{len(filled)} é¡¹å·²å®Œæˆ"

        return json.dumps({"summary": summary.strip()}, ensure_ascii=False, indent=2)

    except Exception as e:
        return json.dumps({"error": f"æ€»ç»“ç”Ÿæˆå¤±è´¥: {str(e)}"}, ensure_ascii=False)

@tool
def confirm_tool(state_json: str) -> str:
    """
    ç¡®è®¤ç« èŠ‚å®Œæˆå¹¶æ›´æ–°çŠ¶æ€

    Args:
        state_json: DocumentStateçš„JSONå­—ç¬¦ä¸²

    Returns:
        ç¡®è®¤ç»“æœå’Œä¸‹ä¸€æ­¥å»ºè®®
    """
    try:
        state_data = json.loads(state_json)
        current_section_idx = state_data.get("current_section", 0)
        section_name = SECTION_NAMES[current_section_idx]

        # æ¨¡æ‹Ÿæ£€æŸ¥æ˜¯å¦æœ‰å…³é”®å†…å®¹æœªå¡«å†™
        filled_count = 5  # æ¨¡æ‹Ÿå·²å¡«å†™5é¡¹å†…å®¹

        if filled_count == 0:
            result = {
                "action": "confirm_rejected",
                "message": "âš ï¸ å½“å‰ç« èŠ‚è¿˜æ²¡æœ‰å¡«å†™ä»»ä½•å†…å®¹ï¼Œè¯·å…ˆå¡«å†™åå†ç¡®è®¤ã€‚",
                "suggestion": "æ‚¨å¯ä»¥ç›´æ¥è¾“å…¥å†…å®¹ï¼Œæˆ–è¯´'é‚£ä½ å†³å®šå§'è®©æˆ‘è‡ªåŠ¨å¡«å†™ã€‚"
            }
        else:
            next_section = current_section_idx + 1
            if next_section < len(SECTION_TITLES):
                result = {
                    "action": "confirm_accepted",
                    "message": f"âœ… ç¬¬{current_section_idx}èŠ‚å·²ç¡®è®¤å®Œæˆï¼",
                    "next_section": next_section,
                    "next_title": SECTION_TITLES[next_section],
                    "suggestion": f"æ¥ä¸‹æ¥æˆ‘ä»¬å°†å¤„ç†ç¬¬{next_section}èŠ‚ï¼š{SECTION_TITLES[next_section]}"
                }
            else:
                result = {
                    "action": "document_complete",
                    "message": "ğŸ‰ æ­å–œï¼æ‰€æœ‰ç« èŠ‚éƒ½å·²å®Œæˆï¼",
                    "suggestion": "æ–‡æ¡£ç”Ÿæˆå®Œæˆï¼Œå¯ä»¥å¯¼å‡ºæœ€ç»ˆç‰ˆæœ¬äº†ã€‚"
                }

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        return json.dumps({"error": f"ç¡®è®¤æ“ä½œå¤±è´¥: {str(e)}"}, ensure_ascii=False)

@tool
def ask_next_tool(state_json: str) -> str:
    """
    ä¸»åŠ¨æé—®ä¸‹ä¸€ä¸ªç« èŠ‚ç›¸å…³ä¿¡æ¯

    Args:
        state_json: DocumentStateçš„JSONå­—ç¬¦ä¸²

    Returns:
        ä¸‹ä¸€ä¸ªç« èŠ‚çš„å¼•å¯¼é—®é¢˜
    """
    try:
        state_data = json.loads(state_json)
        current_section_idx = state_data.get("current_section", 0)

        next_section = current_section_idx + 1
        if next_section >= len(SECTION_TITLES):
            return json.dumps({
                "message": "ğŸ‰ æ‰€æœ‰ç« èŠ‚éƒ½å·²å®Œæˆï¼",
                "suggestion": "å¯ä»¥å¯¼å‡ºå®Œæ•´çš„RWAä»£å¸å‘è¡Œè¯´æ˜ä¹¦äº†ã€‚"
            }, ensure_ascii=False)

        next_title = SECTION_TITLES[next_section]
        next_name = SECTION_NAMES[next_section]

        # æ ¹æ®ä¸‹ä¸€ä¸ªç« èŠ‚ç”Ÿæˆé’ˆå¯¹æ€§é—®é¢˜
        questions_map = {
            0: "è¯·å‘Šè¯‰æˆ‘ä»£å¸çš„åŸºæœ¬ä¿¡æ¯ï¼Œå¦‚ä»£å¸åç§°ã€åˆçº¦åœ°å€ã€èµ„äº§æ€§è´¨ç­‰",
            1: "å…³äºå‘è¡Œä¸»ä½“ï¼Œæ‚¨å¸Œæœ›é‡‡ç”¨ä»€ä¹ˆç»“æ„ï¼Ÿæ¯å­ç»“æ„ã€SPVè¿˜æ˜¯åŸºé‡‘ï¼Ÿ",
            2: "ä»£å¸åˆ†ç±»æ–¹é¢ï¼Œç›®æ ‡å¸‚åœºæ˜¯é¢å‘é›¶å”®ç”¨æˆ·ã€ä¸“ä¸šæŠ•èµ„è€…è¿˜æ˜¯æœºæ„ï¼Ÿ",
            3: "æ³•å¾‹åˆè§„é€‰æ‹©å“ªä¸ªæ³•åŸŸï¼Ÿé¦™æ¸¯ã€æ–°åŠ å¡ã€æ¬§ç›Ÿè¿˜æ˜¯é˜¿è”é…‹ï¼Ÿ",
            4: "Tokenomicsè®¾è®¡ï¼Œæ€»é‡å¤šå°‘ï¼Ÿå›¢é˜Ÿå’Œç”Ÿæ€æ¯”ä¾‹å¦‚ä½•åˆ†é…ï¼Ÿ",
            5: "å‹Ÿé›†å†å²å’Œèµ„é‡‘ç”¨é€”ï¼Œéœ€è¦æŠ«éœ²å“ªäº›ä¿¡æ¯ï¼Ÿ",
            6: "æŠ€æœ¯å®‰å…¨æ–¹é¢ï¼Œé€‰æ‹©å“ªæ¡å…¬é“¾ï¼Ÿå®¡è®¡å’Œæ‰˜ç®¡å¦‚ä½•å®‰æ’ï¼Ÿ",
            7: "ä¸Šå¸‚äº¤æ˜“å®‰æ’ï¼Œé¦–å‘å¹³å°å’Œåšå¸‚ç­–ç•¥ï¼Ÿ",
            8: "å¸‚åœºè¯šä¿¡æªæ–½ï¼ŒKYCå’Œåœ°åŸŸå±è”½å¦‚ä½•è®¾ç½®ï¼Ÿ",
            9: "ä¸»è¦é£é™©æœ‰å“ªäº›éœ€è¦ç‰¹åˆ«è¯´æ˜ï¼Ÿ",
            10: "äº‹ä»¶å“åº”æœºåˆ¶å’Œä¸‹æ¶æµç¨‹ï¼Ÿ",
            11: "æœ€åçš„å£°æ˜å’Œç­¾ç½²æ¡æ¬¾ï¼Ÿ"
        }

        question = questions_map.get(next_section, f"è¯·å¼€å§‹ç¬¬{next_section}èŠ‚çš„å†…å®¹å¡«å†™")

        result = {
            "next_section": next_section,
            "next_title": next_title,
            "guidance_question": question,
            "suggestion": "æ‚¨å¯ä»¥ç›´æ¥å›ç­”ï¼Œæˆ–è€…è¯´'é‚£ä½ å†³å®šå§'è®©æˆ‘æ™ºèƒ½å¡«å†™"
        }

        return json.dumps(result, ensure_ascii=False, indent=2)

    except Exception as e:
        return json.dumps({"error": f"ç”Ÿæˆå¼•å¯¼é—®é¢˜å¤±è´¥: {str(e)}"}, ensure_ascii=False)

# ==================== è¾…åŠ©å‡½æ•° ====================
def get_smart_suggestion(placeholder: str, section_name: str) -> str:
    """åŸºäºå ä½ç¬¦åç§°è·å–æ™ºèƒ½å»ºè®®"""
    placeholder_lower = placeholder.lower()

    # æ‰§è¡Œæ‘˜è¦å»ºè®®
    if "ä»£å¸ç®€ç§°" in placeholder or "token" in placeholder_lower:
        return "CCT (CloudComputer Token)"
    elif "åˆçº¦åœ°å€" in placeholder or "address" in placeholder_lower:
        return "0x1234...5678 (éƒ¨ç½²åå¡«å…¥)"
    elif "èµ„äº§æ€§è´¨" in placeholder:
        return "å€ºæƒ"
    elif "ç›®æ ‡å¸‚åœº" in placeholder:
        return "ä¸“ä¸šæŠ•èµ„è€…ï¼ˆPIï¼‰"
    elif "æ ¸å¿ƒé£é™©" in placeholder:
        return "æŠ€æœ¯å®æ–½ä¸ç›‘ç®¡åˆè§„é£é™©"

    # æ³•å¾‹åˆè§„å»ºè®®
    elif "å…¬å‹Ÿ/ç§å‹Ÿ" in placeholder:
        return "ç§å‹Ÿï¼ˆä¸“ä¸šæŠ•èµ„è€…ï¼Œâ‰¤50äººï¼Œå•ç¬”â‰¥HKD 500kï¼‰"
    elif "æ³•åŸŸ" in placeholder or "é¦™æ¸¯" in placeholder:
        return "é¦™æ¸¯ï¼ˆè¯ç›‘ä¼šç›‘ç®¡ï¼‰"
    elif "kyc" in placeholder_lower:
        return "Chainalysis KYC"

    # Tokenomicså»ºè®®
    elif "æ€»é‡" in placeholder or "supply" in placeholder_lower:
        return "100,000,000"
    elif "å›¢é˜Ÿ" in placeholder and "%" not in placeholder:
        return "15%"
    elif "ç”Ÿæ€" in placeholder and "%" not in placeholder:
        return "35%"
    elif "æµåŠ¨æ€§" in placeholder:
        return "15%"

    # æŠ€æœ¯å®‰å…¨å»ºè®®
    elif "é“¾" in placeholder and "åˆçº¦" in placeholder:
        return "Ethereum Mainnet"
    elif "å®¡è®¡" in placeholder:
        return "CertiK"
    elif "æ‰˜ç®¡" in placeholder:
        return "Fireblocks"

    # é€šç”¨å¡«å†™
    elif "æ—¥æœŸ" in placeholder or "date" in placeholder_lower:
        return datetime.now().strftime("%Y-%m-%d")
    elif "åç§°" in placeholder and "name" in placeholder_lower:
        return "CloudComputer Technology Ltd."
    elif "é‚®ç®±" in placeholder or "email" in placeholder_lower:
        return "compliance@cloudcomputer.com"
    else:
        return f"[å¾…å®Œå–„ï¼š{placeholder}]"

def state_to_json(state: DocumentState) -> str:
    """å°†DocumentStateè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²"""
    return json.dumps({
        k: v for k, v in state.items()
        if k != "conversation_history"  # æ’é™¤è¿‡é•¿çš„å¯¹è¯å†å²
    }, ensure_ascii=False, indent=2, default=str)

# ==================== Agentå±‚ ====================
def initialize_agent():
    """åˆå§‹åŒ–Agentï¼Œé›†æˆæ‰€æœ‰å·¥å…·"""

    # åˆå§‹åŒ–LLM
    llm = ChatOpenAI(
        base_url="https://apis.iflow.cn/v1",
        api_key="sk-34d42e4c747d1bdf0f02beaca589cd38",
        model="kimi-k2",
        temperature=0.1
    )

    # å·¥å…·åˆ—è¡¨
    tools = [
        extract_info_tool,
        autofill_tool,
        summarize_tool,
        confirm_tool,
        ask_next_tool
    ]

    # Agent Prompt
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ä½ æ˜¯CloudComputer RWAä»£å¸å‘è¡Œè¯´æ˜ä¹¦æ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“ä¸šçš„é¡¹ç›®åˆä¼™äººã€‚

ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©ç”¨æˆ·å®Œæˆ12ä¸ªç« èŠ‚çš„RWAä»£å¸å‘è¡Œè¯´æ˜ä¹¦ç¼–å†™ã€‚

ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ä»¥ä½¿ç”¨ï¼š
1. extract_info_tool: æå–ç”¨æˆ·è¾“å…¥çš„ç»“æ„åŒ–ä¿¡æ¯
2. autofill_tool: æ ¹æ®ä¸Šä¸‹æ–‡è‡ªåŠ¨å¡«å†™æœªå®Œæˆå†…å®¹
3. summarize_tool: æ€»ç»“å½“å‰ç« èŠ‚å®Œæˆæƒ…å†µ
4. confirm_tool: ç¡®è®¤ç« èŠ‚å®ŒæˆçŠ¶æ€
5. ask_next_tool: ä¸»åŠ¨å¼•å¯¼ä¸‹ä¸€ä¸ªç« èŠ‚

å·¥ä½œæµç¨‹ï¼š
1. ç†è§£ç”¨æˆ·è‡ªç„¶è¯­è¨€è¾“å…¥
2. ä½¿ç”¨extract_info_toolæå–å…³é”®ä¿¡æ¯
3. æ ¹æ®ç”¨æˆ·æ„å›¾é€‰æ‹©åˆé€‚çš„å·¥å…·
4. æä¾›æ™ºèƒ½å¡«å†™å»ºè®®æˆ–è‡ªåŠ¨å®Œæˆ
5. ç¡®è®¤åè¿›å…¥ä¸‹ä¸€ç« èŠ‚

è¯·å§‹ç»ˆä¿æŒä¸“ä¸šã€å‹å¥½çš„è¯­æ°”ï¼Œç”¨ä¸­æ–‡å›å¤ã€‚"""),
        ("user", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad"),
    ])

    # åˆ›å»ºAgent
    agent = create_openai_tools_agent(llm, tools, prompt)
    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,
        handle_parsing_errors=True,
        max_iterations=15
    )

    return agent_executor

# ==================== Graphå±‚ ====================
def handle_input(state: DocumentState) -> DocumentState:
    """å¤„ç†ç”¨æˆ·è¾“å…¥èŠ‚ç‚¹"""
    print(f"\nğŸ“ å½“å‰å¤„ç†ç¬¬{state['current_section']}èŠ‚ï¼š{SECTION_TITLES[state['current_section']]}")

    # è·å–ç”¨æˆ·è¾“å…¥
    user_input = input(f"\nğŸ’¬ è¯·è¾“å…¥å†…å®¹ï¼ˆæˆ–è¯´'é‚£ä½ å†³å®šå§'è®©AIæ™ºèƒ½å¡«å†™ï¼‰ï¼š").strip()

    # æ›´æ–°çŠ¶æ€
    state["last_user_input"] = user_input
    state["conversation_history"].append({
        "role": "user",
        "content": user_input,
        "section": state["current_section"]
    })

    return state

def process_with_agent(state: DocumentState) -> DocumentState:
    """ä½¿ç”¨Agentå¤„ç†ç”¨æˆ·è¾“å…¥"""
    agent_executor = initialize_agent()

    try:
        # æ„å»ºAgentè¾“å…¥
        user_input = state["last_user_input"]
        state_json = state_to_json(state)

        agent_input = f"""
ç”¨æˆ·è¾“å…¥ï¼š{user_input}

å½“å‰çŠ¶æ€ï¼š
{state_json}

è¯·æ ¹æ®ç”¨æˆ·è¾“å…¥å’Œå½“å‰çŠ¶æ€ï¼Œé€‰æ‹©åˆé€‚çš„å·¥å…·æ¥å¤„ç†ã€‚
"""

        # æ‰§è¡ŒAgent
        result = agent_executor.invoke({"input": agent_input})

        # ä¿å­˜Agentå“åº”
        state["agent_response"] = result.get("output", "")
        state["conversation_history"].append({
            "role": "assistant",
            "content": state["agent_response"],
            "section": state["current_section"]
        })

        # è§£æAgentçš„å·¥å…·è°ƒç”¨ç»“æœ
        tool_output = result.get("output", "")

        if "è‡ªåŠ¨å¡«å†™" in tool_output or "autofill" in tool_output.lower():
            state["interaction_mode"] = "fill"
        elif "ç¡®è®¤" in tool_output or "confirm" in tool_output.lower():
            state["interaction_mode"] = "confirm"
        elif "æ€»ç»“" in tool_output or "summarize" in tool_output.lower():
            state["interaction_mode"] = "ask"
        else:
            state["interaction_mode"] = "auto"

        print(f"\nğŸ¤– æ™ºèƒ½åŠ©æ‰‹ï¼š{state['agent_response']}")

    except Exception as e:
        error_msg = f"Agentå¤„ç†å‡ºé”™: {str(e)}"
        print(f"\nâŒ {error_msg}")
        state["agent_response"] = error_msg

    return state

def confirm_section(state: DocumentState) -> DocumentState:
    """ç¡®è®¤ç« èŠ‚å®ŒæˆèŠ‚ç‚¹"""
    current_section = state["current_section"]
    section_name = SECTION_NAMES[current_section]

    # æ¨¡æ‹Ÿæ£€æŸ¥ç« èŠ‚å®Œæˆæƒ…å†µ
    filled_count = 5  # æ¨¡æ‹Ÿå·²å¡«å†™5é¡¹å†…å®¹

    if filled_count > 0:
        print(f"\nâœ… ç¬¬{current_section}èŠ‚ {SECTION_TITLES[current_section]} å·²å®Œæˆ")
        print(f"   å¡«å†™å†…å®¹ï¼š{filled_count} é¡¹")

        # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç¡®è®¤
        confirm = input(f"\nğŸ“Œ ç¡®è®¤å®Œæˆå¹¶ç»§ç»­ä¸‹ä¸€èŠ‚å—ï¼Ÿ(y/n): ").strip().lower()

        if confirm in ['y', 'yes', 'æ˜¯']:
            state["section_complete"] = True
            state["current_section"] += 1
            print(f"âœ… å·²ç¡®è®¤ï¼Œè¿›å…¥ä¸‹ä¸€èŠ‚...")
        else:
            state["section_complete"] = False
            print("ğŸ“ ç»§ç»­å®Œå–„å½“å‰ç« èŠ‚...")
    else:
        print("âš ï¸ å½“å‰ç« èŠ‚è¿˜æ²¡æœ‰å¡«å†™å†…å®¹ï¼Œè¯·å…ˆå¡«å†™ã€‚")
        state["section_complete"] = False

    return state

# ==================== æ„å»ºLangGraph ====================
def build_intelligent_agent():
    """æ„å»ºæ™ºèƒ½äº¤äº’Agentçš„LangGraph"""

    # åˆ›å»ºStateGraph
    workflow = StateGraph(DocumentState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("initialize", initialize_document)
    workflow.add_node("handle_input", handle_input)
    workflow.add_node("process_agent", process_with_agent)
    workflow.add_node("confirm_section", confirm_section)

    # æ·»åŠ è¾¹
    workflow.add_edge(START, "initialize")
    workflow.add_edge("initialize", "handle_input")
    workflow.add_edge("handle_input", "process_agent")
    workflow.add_edge("process_agent", "confirm_section")

    # æ¡ä»¶è¾¹ï¼šæ˜¯å¦ç»§ç»­å¤„ç†
    def should_continue(state: DocumentState) -> Literal["handle_input", END]:
        if state["current_section"] >= len(SECTION_TITLES):
            return END

        if not state["section_complete"]:
            return "handle_input"
        else:
            return "handle_input"

    workflow.add_conditional_edges("confirm_section", should_continue,
                                  {"handle_input": "handle_input", END: END})

    # ç¼–è¯‘graph
    app = workflow.compile(checkpointer=InMemorySaver())

    return app

def initialize_document(state: DocumentState) -> DocumentState:
    """åˆå§‹åŒ–æ–‡æ¡£çŠ¶æ€"""
    print("=" * 60)
    print("ğŸ¤ CloudComputer RWAä»£å¸å‘è¡Œè¯´æ˜ä¹¦ - æ™ºèƒ½äº¤äº’Agentç³»ç»Ÿ")
    print("=" * 60)
    print("ğŸš€ åŸºäºLangGraphçš„å¤šå·¥å…·Graphæ¶æ„")
    print("ğŸ¤– é›†æˆæ™ºèƒ½Agentï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€ç†è§£å’Œè‡ªåŠ¨å¡«å†™")
    print("ğŸ“‹ å…±æœ‰12ä¸ªä¸»è¦ç« èŠ‚éœ€è¦å®Œæˆ")
    print("=" * 60)

    # åˆå§‹åŒ–çŠ¶æ€
    return {
        **state,
        "current_section": 0,
        "section_contents": {name: "" for name in SECTION_NAMES},
        "filled_placeholders": {name: {} for name in SECTION_NAMES},
        "pending_placeholders": {name: [] for name in SECTION_NAMES},
        "interaction_mode": "ask",
        "conversation_history": [],
        "last_user_input": "",
        "ai_summary": "",
        "agent_response": "",
        "section_complete": False,
        "extracted_info": {}
    }

# ==================== ä¸»è¦è¿è¡Œå‡½æ•° ====================
def run_intelligent_agent():
    """è¿è¡Œæ™ºèƒ½äº¤äº’Agentç³»ç»Ÿ"""

    # æ„å»ºAgent
    agent = build_intelligent_agent()

    # è¿è¡Œä¼šè¯
    config = {"configurable": {"thread_id": "intelligent_agent_session"}}

    try:
        result = agent.invoke({}, config)

        print("\n" + "="*60)
        print("ğŸ‰ æ™ºèƒ½Agentç³»ç»Ÿè¿è¡Œå®Œæˆï¼")
        print("="*60)
        print(f"æœ€ç»ˆçŠ¶æ€:")
        print(f"- å¤„ç†ç« èŠ‚: {result.get('current_section', 'N/A')}/{len(SECTION_TITLES)}")
        print(f"- å¯¹è¯è½®æ•°: {len(result.get('conversation_history', []))}")
        print(f"- äº¤äº’æ¨¡å¼: {result.get('interaction_mode', 'N/A')}")

        # ä¿å­˜ç»“æœ
        save_final_document(result)

    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼æ‚¨çš„å·¥ä½œå·²ä¿å­˜ã€‚")
    except Exception as e:
        print(f"\nâŒ å‡ºç°é”™è¯¯: {e}")

def save_final_document(state: Dict):
    """ä¿å­˜æœ€ç»ˆæ–‡æ¡£"""
    output_file = "completed_intelligent_memo.md"

    # ç”Ÿæˆå®Œæ•´æ–‡æ¡£å†…å®¹
    document_content = f"""# CloudComputer RWAä»£å¸å‘è¡Œè¯´æ˜ä¹¦

## ç”Ÿæˆä¿¡æ¯
- ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- å¤„ç†ç« èŠ‚æ•°: {state.get('current_section', 0)}
- å¯¹è¯è½®æ•°: {len(state.get('conversation_history', []))}

## ç« èŠ‚å®Œæˆæƒ…å†µ
"""

    for i, title in enumerate(SECTION_TITLES):
        if i < state.get('current_section', 0):
            document_content += f"âœ… ç¬¬{i}èŠ‚ {title}\n"
        else:
            document_content += f"â¸ï¸ ç¬¬{i}èŠ‚ {title}\n"

    document_content += f"""

## å¯¹è¯å†å²æ‘˜è¦
æœ€è¿‘å‡ è½®å¯¹è¯ï¼š
"""

    history = state.get('conversation_history', [])[-5:]  # å–æœ€å5è½®å¯¹è¯
    for item in history:
        role = "ç”¨æˆ·" if item['role'] == 'user' else "åŠ©æ‰‹"
        document_content += f"- {role}: {item['content'][:100]}...\n"

    # ä¿å­˜åˆ°æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(document_content)

    print(f"\nğŸ’¾ å·²ä¿å­˜å®Œæ•´æ–‡æ¡£åˆ°: {output_file}")

    # ä¿å­˜çŠ¶æ€åˆ°JSONæ–‡ä»¶
    with open("intelligent_agent_state.json", "w", encoding="utf-8") as f:
        json.dump({
            "state": {k: v for k, v in state.items() if k != "conversation_history"},
            "completed_sections": state.get("current_section", 0),
            "conversation_count": len(state.get("conversation_history", []))
        }, f, ensure_ascii=False, indent=2, default=str)

# ==================== ç¤ºä¾‹å’Œæµ‹è¯•ä»£ç  ====================
if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨CloudComputer RWAæ™ºèƒ½äº¤äº’Agentç³»ç»Ÿ...")
    print("ğŸ“‹ è¿™æ˜¯ä¸€ä¸ªåŸºäºLangGraphçš„å¤šå·¥å…·ã€å¤šèŠ‚ç‚¹graph-basedæ™ºèƒ½äº¤äº’ç³»ç»Ÿ")
    print("ğŸ¤– é›†æˆäº†Agentå±‚ï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€ç†è§£å’Œæ™ºèƒ½å·¥å…·è°ƒç”¨")
    print("âœ¨ åŠŸèƒ½ç‰¹è‰²ï¼š")
    print("   â€¢ å¤šå·¥å…·å±‚ï¼šä¿¡æ¯æå–ã€è‡ªåŠ¨å¡«å†™ã€æ€»ç»“ç¡®è®¤ã€æ™ºèƒ½å¼•å¯¼")
    print("   â€¢ Agentå±‚ï¼šè‡ªç„¶è¯­è¨€è§£æ + åŠ¨æ€å·¥å…·è°ƒç”¨")
    print("   â€¢ Graphå±‚ï¼šçŠ¶æ€æµè½¬ç®¡ç†ï¼Œæ”¯æŒäº¤äº’å¼æ–‡æ¡£ç”Ÿæˆ")
    print("   â€¢ æ™ºèƒ½äº¤äº’ï¼šç†è§£ç”¨æˆ·æ„å›¾ï¼Œè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å·¥å…·")
    print("=" * 60)

    # å¯åŠ¨ç³»ç»Ÿ
    run_intelligent_agent()